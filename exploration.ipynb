{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import initializers\n",
    "\n",
    "class InstanceNorm(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.omicron = tf.Variable(np.zeros(self.hidden_channels), dtype='float32')\n",
    "        self.eta = tf.Variable(np.random.rand(self.hidden_channels), dtype='float32')\n",
    "        self.delta = tf.Variable(np.zeros(self.hidden_channels)+0.1, dtype='float32')\n",
    "\n",
    "    def call(self, r):\n",
    "        '''\n",
    "        Param: r, a 4D tensor, b x h x w x c, where b = 1\n",
    "        Return: a tensor normalized with the same size as r.\n",
    "        '''                \n",
    "        return tf.convert_to_tensor([self.omicron + self.delta * (r[0] - tf.math.reduce_mean(r[0], axis=(0, 1)))\\\n",
    "                         /(tf.math.sqrt(tf.math.reduce_variance(r[0], axis=(0, 1))+self.eta))])\n",
    "\n",
    "class fGRU(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Generates an fGRUCell\n",
    "    params:\n",
    "    hidden_channels: the number of channels which is constant throughout the\n",
    "                     processing of each unit\n",
    "    '''\n",
    "    def __init__(self, input_shape, kernel_size=3, padding='same', use_attention=0, channel_sym = False):\n",
    "        # channel_sym assigned False for speed. Saves 30 seconds.\n",
    "\n",
    "        super().__init__()\n",
    "        self.hidden_channels = input_shape[-1]\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.channel_sym = channel_sym\n",
    "        self.use_attention = use_attention\n",
    "        self.input_shape_ = input_shape\n",
    "\n",
    "        if self.use_attention:\n",
    "            # TODO: implement attention\n",
    "            pass\n",
    "        else:\n",
    "            # Initialize convolutional kernels\n",
    "            self.U_a = layers.Conv2D(\n",
    "                filters=self.hidden_channels,\n",
    "                kernel_size=1, \n",
    "                strides=1, \n",
    "                padding=self.padding,\n",
    "                kernel_initializer=initializers.Orthogonal(),\n",
    "                )\n",
    "            \n",
    "            self.U_m = layers.Conv2D(\n",
    "                filters=1,\n",
    "                kernel_size=self.kernel_size, \n",
    "                strides=1, \n",
    "                padding=self.padding,\n",
    "                kernel_initializer=initializers.Orthogonal(),\n",
    "                )\n",
    "            \n",
    "            self.W_s = layers.Conv2D(\n",
    "                filters=self.hidden_channels,\n",
    "                kernel_size=self.kernel_size, \n",
    "                strides=1, \n",
    "                padding=self.padding,\n",
    "                kernel_initializer=initializers.Orthogonal(),\n",
    "                )\n",
    "            \n",
    "            self.U_f = layers.Conv2D(\n",
    "                filters=self.hidden_channels,\n",
    "                kernel_size=self.kernel_size, \n",
    "                strides=1, \n",
    "                padding=self.padding,\n",
    "                kernel_initializer=initializers.Orthogonal(),\n",
    "                )\n",
    "            \n",
    "            self.W_f = layers.Conv2D(\n",
    "                filters=self.hidden_channels,\n",
    "                kernel_size=self.kernel_size, \n",
    "                strides=1, \n",
    "                padding=self.padding,\n",
    "                kernel_initializer=initializers.Orthogonal(),\n",
    "                )\n",
    "        self.build(self.input_shape_)\n",
    "\n",
    "        # initiate other weights\n",
    "        self.alpha = tf.Variable(0.1, dtype='float32')\n",
    "        self.mu = tf.Variable(0, dtype='float32')\n",
    "        self.nu = tf.Variable(0, dtype='float32')\n",
    "        self.omega = tf.Variable(0.1, dtype='float32')\n",
    "\n",
    "    def channel_symmetrize(self):\n",
    "        '''\n",
    "        symmetrize the kernels channel-wise\n",
    "        Somehow, if I write it in init, there will be the following error:\n",
    "        'Conv2D' does not have attribute 'kernel'.\n",
    "        '''\n",
    "        if self.channel_sym: \n",
    "            for i in range(self.hidden_channels):\n",
    "                for j in range(i, self.hidden_channels):\n",
    "                    self.U_a.kernel[:,:,i,j].assign(self.U_a.kernel[:,:,j,i])\n",
    "                    self.U_f.kernel[:,:,i,j].assign(self.U_f.kernel[:,:,j,i])\n",
    "                    self.W_s.kernel[:,:,i,j].assign(self.W_s.kernel[:,:,j,i])\n",
    "                    self.W_f.kernel[:,:,i,j].assign(self.W_f.kernel[:,:,j,i])\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.U_a.build(input_shape)\n",
    "        self.U_m.build(input_shape)\n",
    "        self.U_f.build(input_shape)\n",
    "        self.W_s.build(input_shape)\n",
    "        self.W_f.build(input_shape)\n",
    "        if self.channel_sym:\n",
    "            self.channel_symmetrize()\n",
    "        \n",
    "        # initialize instance norm layers\n",
    "        self.iN1 = InstanceNorm(self.hidden_channels)\n",
    "        self.iN2 = InstanceNorm(self.hidden_channels)\n",
    "        self.iN3 = InstanceNorm(self.hidden_channels)\n",
    "        self.iN4 = InstanceNorm(self.hidden_channels)\n",
    "\n",
    "\n",
    "    def call(self, z, h):\n",
    "        '''\n",
    "        Params: \n",
    "        Z: output from the last layer if fGRU-horizontal, hidden state of the\n",
    "        current layer at t if fGRU-feedback.\n",
    "        H: hidden state of the current layer at t-1 if fGRU-horizontal, output\n",
    "        from the next layer if fGRU-feedback.\n",
    "        '''\n",
    "\n",
    "        # Stage 1: suppression\n",
    "        a_s = self.U_a(h) # Compute channel-wise selection\n",
    "        m_s = self.U_m(h) # Compute spatial selection\n",
    "        # (note that U_a and U_m are kernels of different sizes and therefore\n",
    "        # have different functions)\n",
    "\n",
    "        m_s_expanded = tf.transpose(tf.convert_to_tensor([tf.transpose(m_s)[0]]*self.hidden_channels))\n",
    "        g_s = tf.sigmoid(self.iN1(a_s * m_s_expanded))\n",
    "        # Compute suppression gate\n",
    "        c_s = self.iN2(self.W_s(h * g_s))\n",
    "        # compute suppression interactions\n",
    "        S = tf.keras.activations.relu(z - tf.keras.activations.relu((self.alpha * h + self.mu)*c_s))\n",
    "        # Additive and multiplicative suppression of Z\n",
    "\n",
    "        # Stage 2: facilitation\n",
    "        g_f = tf.sigmoid(self.iN3(self.U_f(S)))\n",
    "        # Compute channel-wise recurrent updates\n",
    "        c_f = self.iN4(self.W_f(S))\n",
    "        # Compute facilitation interactions\n",
    "        h_tilda = tf.keras.activations.relu(self.nu*(c_f + S) + self.omega*(c_f * S))\n",
    "        # Additive and multiplicative facilitation of S\n",
    "        ht = (1 - g_f) * h + g_f * h_tilda\n",
    "        # Update recurrent state\n",
    "        return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 00:51:43.846934: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.07984334 0.11455605 0.163245   ... 0.17957237 0.0634892\n",
      "    0.4242353 ]\n",
      "   [0.01165117 0.3060048  0.45316622 ... 0.0485071  0.32089683\n",
      "    0.4126587 ]\n",
      "   [0.3190008  0.18126743 0.1159981  ... 0.08572371 0.24778576\n",
      "    0.3925361 ]\n",
      "   ...\n",
      "   [0.4006103  0.29275915 0.37584186 ... 0.4716049  0.462499\n",
      "    0.35205117]\n",
      "   [0.02333889 0.20960535 0.43413654 ... 0.4586685  0.16885658\n",
      "    0.3135927 ]\n",
      "   [0.33670387 0.33334872 0.18522047 ... 0.2495065  0.07325691\n",
      "    0.3886185 ]]\n",
      "\n",
      "  [[0.05987698 0.35893238 0.18363668 ... 0.04022368 0.12781082\n",
      "    0.13562593]\n",
      "   [0.07062237 0.3909683  0.48119456 ... 0.1932039  0.02582544\n",
      "    0.15836316]\n",
      "   [0.00128846 0.27886367 0.21333492 ... 0.446795   0.17821662\n",
      "    0.4759597 ]\n",
      "   ...\n",
      "   [0.28442866 0.17637363 0.49467507 ... 0.39762995 0.22101052\n",
      "    0.1840567 ]\n",
      "   [0.35709444 0.37761354 0.04195167 ... 0.23620974 0.21628556\n",
      "    0.17500621]\n",
      "   [0.21945629 0.07619277 0.3555263  ... 0.24796298 0.16033842\n",
      "    0.21940245]]\n",
      "\n",
      "  [[0.41433257 0.48755026 0.02650535 ... 0.26937655 0.4819549\n",
      "    0.1133769 ]\n",
      "   [0.36111832 0.20555314 0.4017736  ... 0.28323355 0.22732738\n",
      "    0.1176808 ]\n",
      "   [0.27383998 0.02170639 0.34689346 ... 0.31586182 0.15563141\n",
      "    0.04467865]\n",
      "   ...\n",
      "   [0.00458975 0.15232973 0.16306108 ... 0.2767945  0.30271736\n",
      "    0.14380886]\n",
      "   [0.14302789 0.05593468 0.42772326 ... 0.01501665 0.0185199\n",
      "    0.15990534]\n",
      "   [0.09985532 0.33934587 0.02957881 ... 0.37440336 0.01213186\n",
      "    0.24398705]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.31283313 0.14737757 0.04188156 ... 0.20212123 0.05391216\n",
      "    0.43525288]\n",
      "   [0.3192166  0.48554713 0.38235128 ... 0.43309554 0.23479603\n",
      "    0.15495738]\n",
      "   [0.5016082  0.10661767 0.05867621 ... 0.46356484 0.44124812\n",
      "    0.25217053]\n",
      "   ...\n",
      "   [0.42085025 0.04701758 0.05276691 ... 0.22721569 0.39369217\n",
      "    0.3778268 ]\n",
      "   [0.07529841 0.11364295 0.0945477  ... 0.1193746  0.15563838\n",
      "    0.22220996]\n",
      "   [0.17662248 0.03462927 0.35063344 ... 0.3630464  0.24782212\n",
      "    0.4827768 ]]\n",
      "\n",
      "  [[0.2246072  0.39649773 0.40684238 ... 0.01016405 0.09975682\n",
      "    0.24875532]\n",
      "   [0.36234087 0.23851693 0.13927302 ... 0.50260025 0.433069\n",
      "    0.2819591 ]\n",
      "   [0.2012217  0.19597434 0.38577154 ... 0.21791512 0.06959031\n",
      "    0.47778332]\n",
      "   ...\n",
      "   [0.37650365 0.09021194 0.29425162 ... 0.02092147 0.36835983\n",
      "    0.22492445]\n",
      "   [0.04427922 0.24379438 0.06149602 ... 0.45013535 0.40298748\n",
      "    0.08200012]\n",
      "   [0.05113852 0.31771997 0.34298158 ... 0.19144209 0.04619581\n",
      "    0.43588924]]\n",
      "\n",
      "  [[0.16361915 0.06484881 0.2704751  ... 0.21432449 0.05473759\n",
      "    0.07199592]\n",
      "   [0.3052191  0.38598183 0.22117485 ... 0.35445103 0.15078144\n",
      "    0.33195984]\n",
      "   [0.02932633 0.38072416 0.30377007 ... 0.20652178 0.01795281\n",
      "    0.09633256]\n",
      "   ...\n",
      "   [0.14813963 0.37737358 0.4237059  ... 0.29245222 0.53428125\n",
      "    0.21463014]\n",
      "   [0.26065895 0.04048919 0.40604594 ... 0.30716845 0.3156599\n",
      "    0.29257098]\n",
      "   [0.07071001 0.37471604 0.09165506 ... 0.38124081 0.22721864\n",
      "    0.46544993]]]\n",
      "\n",
      "\n",
      " [[[0.08168502 0.18547155 0.05340808 ... 0.1405224  0.18054408\n",
      "    0.0441527 ]\n",
      "   [0.335892   0.08144291 0.13175571 ... 0.30998525 0.39280638\n",
      "    0.29292157]\n",
      "   [0.4037992  0.26826778 0.05424561 ... 0.24469343 0.19543721\n",
      "    0.30021635]\n",
      "   ...\n",
      "   [0.12356299 0.08098559 0.17878847 ... 0.25637013 0.01950335\n",
      "    0.24191709]\n",
      "   [0.27349067 0.39591974 0.11654171 ... 0.15424815 0.13605644\n",
      "    0.11670192]\n",
      "   [0.26436618 0.17740045 0.21807708 ... 0.02292511 0.37578598\n",
      "    0.3381563 ]]\n",
      "\n",
      "  [[0.10676259 0.40634614 0.10210373 ... 0.22544846 0.3716475\n",
      "    0.17721926]\n",
      "   [0.14476229 0.3844458  0.21108061 ... 0.4825619  0.08134491\n",
      "    0.31033298]\n",
      "   [0.01712199 0.42026627 0.2642967  ... 0.26872247 0.4549713\n",
      "    0.16436641]\n",
      "   ...\n",
      "   [0.46354732 0.45612448 0.22754139 ... 0.22673678 0.41357014\n",
      "    0.28175429]\n",
      "   [0.35508695 0.2694417  0.4024046  ... 0.16542803 0.264223\n",
      "    0.47022697]\n",
      "   [0.1670038  0.42494425 0.49293298 ... 0.03003951 0.50602984\n",
      "    0.02898907]]\n",
      "\n",
      "  [[0.11923566 0.44759953 0.48189735 ... 0.3179368  0.26104483\n",
      "    0.20050366]\n",
      "   [0.2023221  0.308273   0.3377222  ... 0.06112494 0.13560404\n",
      "    0.00534181]\n",
      "   [0.40199223 0.4528335  0.46377835 ... 0.19460401 0.19547442\n",
      "    0.35010463]\n",
      "   ...\n",
      "   [0.47618768 0.4826219  0.01314425 ... 0.35034806 0.0620562\n",
      "    0.4865415 ]\n",
      "   [0.17729871 0.19320129 0.348938   ... 0.18378843 0.18001047\n",
      "    0.06748678]\n",
      "   [0.33850062 0.46229857 0.35130507 ... 0.1271918  0.46274644\n",
      "    0.48273328]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34852755 0.15038235 0.06285442 ... 0.12919247 0.27702433\n",
      "    0.24886012]\n",
      "   [0.07310306 0.08883211 0.28319687 ... 0.08750029 0.04656081\n",
      "    0.29997018]\n",
      "   [0.2652085  0.4598235  0.04942674 ... 0.3349165  0.32060796\n",
      "    0.02639664]\n",
      "   ...\n",
      "   [0.10465929 0.18819281 0.03866705 ... 0.33362854 0.2906863\n",
      "    0.37753758]\n",
      "   [0.00213137 0.10674491 0.35393402 ... 0.4476092  0.00155322\n",
      "    0.48687825]\n",
      "   [0.196088   0.29048553 0.22111735 ... 0.2802685  0.15275414\n",
      "    0.47863233]]\n",
      "\n",
      "  [[0.27037236 0.20067813 0.04345956 ... 0.2773205  0.21991684\n",
      "    0.16873623]\n",
      "   [0.33818972 0.14544939 0.13283035 ... 0.16924997 0.3093675\n",
      "    0.0693556 ]\n",
      "   [0.20832512 0.08895195 0.28083962 ... 0.09827709 0.00233762\n",
      "    0.16369754]\n",
      "   ...\n",
      "   [0.51743394 0.11067905 0.11246359 ... 0.34660482 0.00722801\n",
      "    0.17490362]\n",
      "   [0.15235832 0.38702103 0.32023922 ... 0.01927499 0.15344775\n",
      "    0.45577174]\n",
      "   [0.4710553  0.0074839  0.00464731 ... 0.45725003 0.15188746\n",
      "    0.08748759]]\n",
      "\n",
      "  [[0.42841125 0.01030229 0.27477875 ... 0.05000564 0.0776227\n",
      "    0.29607356]\n",
      "   [0.16977666 0.03157165 0.00666894 ... 0.4462168  0.28921452\n",
      "    0.3147289 ]\n",
      "   [0.08182697 0.24695559 0.04284844 ... 0.3591003  0.22869377\n",
      "    0.47209987]\n",
      "   ...\n",
      "   [0.41223487 0.00379199 0.11064434 ... 0.20489535 0.19665001\n",
      "    0.23017387]\n",
      "   [0.00902898 0.00608346 0.04480971 ... 0.1873425  0.49103183\n",
      "    0.30168924]\n",
      "   [0.3773653  0.31721866 0.07141017 ... 0.45979208 0.41763082\n",
      "    0.44550988]]]], shape=(2, 24, 24, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "testCell = fGRU([2, 24, 24, 64])\n",
    "\n",
    "image = np.random.rand(2, 24, 24, 64)\n",
    "H = np.random.rand(2, 24, 24, 64)\n",
    "\n",
    "out = testCell(image, H)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "import fGRU\n",
    "\n",
    "class GammaNetBlock(layers.Layer):\n",
    "    '''\n",
    "    Generate a block in gamma-net\n",
    "    '''\n",
    "    def __init__(self, batch_size, input_shape, layers_config):\n",
    "        '''\n",
    "        params: \n",
    "        input_channels: int, the number of input channels\n",
    "        hidden_channels: int, the number of channels within the block\n",
    "        layers: a list of tuples, specifying what kind of layers it contains:\n",
    "                Conv2D: ('c', [kernel_size, strides])\n",
    "                TransposedConv2D: ('t', [kernel_size, strides])\n",
    "                fGru: ('f', [input_shape, use_attention])\n",
    "                maxPool: ('m', [kernel_size, strides])\n",
    "                instanceNorm: ('i')\n",
    "                denselayer: ('d', [unit])\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.input_shape_ = [batch_size, input_shape[0], input_shape[1], input_shape[2]]\n",
    "        # here, input_shape_ is in [batch_size, height, width, channel_size]\n",
    "\n",
    "        self.hidden_channels = self.input_shape_[-1]\n",
    "        self.fgru = None\n",
    "        self.hidden_state = tf.Variable(tf.zeros(self.input_shape_), trainable=False)\n",
    "        self.layers_config = layers_config\n",
    "        self.layers = []\n",
    "\n",
    "        for layer in layers_config:\n",
    "        # populate the blocks with layers\n",
    "            if layer[0] == 'c':\n",
    "                kernel_size = layer[1][0]\n",
    "                strides = layer[1][1]\n",
    "                self.layers.append(layers.Conv2D(\n",
    "                    filters=self.hidden_channels, \n",
    "                    kernel_size=kernel_size, \n",
    "                    strides=strides,\n",
    "                    padding='same',\n",
    "                    activation='ReLU'\n",
    "                    ))\n",
    "                \n",
    "            elif layer[0] == 't':\n",
    "                kernel_size = layer[1][0]\n",
    "                strides = layer[1][1]\n",
    "                self.layers.append(layers.Conv2DTranspose(\n",
    "                    filters=self.hidden_channels, \n",
    "                    kernel_size=kernel_size, \n",
    "                    strides=strides,\n",
    "                    padding='same' \n",
    "                    ))\n",
    "                \n",
    "            elif layer[0] == 'f':\n",
    "                kernel_size = layer[1][0]\n",
    "                use_attention = layer[1][1]\n",
    "                self.fgru=fGRU.fGRU(\n",
    "                    input_shape=self.input_shape_, \n",
    "                    kernel_size=kernel_size,\n",
    "                    use_attention = use_attention,\n",
    "                    )\n",
    "                self.layers.append(self.fgru)\n",
    "\n",
    "            elif layer[0] == 'm':\n",
    "                pool_size = layer[1][0]\n",
    "                strides = layer[1][1]\n",
    "                self.layers.append(layers.MaxPool2D(\n",
    "                    pool_size=pool_size, \n",
    "                    strides=strides,\n",
    "                    padding='valid' \n",
    "                    ))\n",
    "                \n",
    "            elif layer[0] == 'i':\n",
    "                self.layers.append(fGRU.InstanceNorm(self.hidden_channels))\n",
    "\n",
    "            elif layer[0] == 'd':\n",
    "                unit = layer[1][0]\n",
    "                if layer[1][1] == 's':\n",
    "                    self.layers.append(layers.Dense(unit, activation='softmax'))\n",
    "                elif layer[1][1] == 'l':\n",
    "                    self.layers.append(layers.Dense(unit, activation='leaky_relu'))\n",
    "\n",
    "            elif layer[0] == 'l':\n",
    "                self.layers.append(layers.Flatten())\n",
    "\n",
    "    def call(self, x, h):\n",
    "        z = x\n",
    "        for layer in self.layers:\n",
    "            if layer == self.fgru:\n",
    "                z = layer(z, h)\n",
    "                self.hidden_state.assign(z)\n",
    "            else:\n",
    "                z = layer(z)\n",
    "        return z\n",
    "\n",
    "# in each layer, there are three lists: \n",
    "# input shape (without batch_size), bottom-up unit, top-down unit (if any)\n",
    "default_config = [\n",
    "    [[384, 384, 24], \n",
    "     [('c', [3, 1]), ('c', [3, 1]), ('f', [9, False]), ('m', [2, 2])],\n",
    "     [('t', [4, 2]),('c', [3, 1]),('i'),('f', [1, False])]], # first layer\n",
    "    [[192, 192, 28], \n",
    "     [('c', [3, 1]), ('f', [7, False]), ('m', [2, 2])],\n",
    "     [('t', [4, 2]),('c', [3, 1]),('i'),('f', [1, False])]], # second layer\n",
    "    [[96, 96, 36], \n",
    "     [('c', [3, 1]), ('f', [5, False]), ('m', [2, 2])],\n",
    "     [('t', [4, 2]),('c', [3, 1]),('i'),('f', [1, False])]], # third layer\n",
    "    [[48, 48, 48], \n",
    "     [('c', [3, 1]), ('f', [3, False]), ('m', [2, 2])],\n",
    "     [('t', [4, 2]),('c', [3, 1]),('i'),('f', [1, False])]], # forth layer\n",
    "    [[24, 24, 64], \n",
    "     [('c', [3, 1]), ('f', [3, False])]], # fifth layer\n",
    "    [[384, 384, 24], [('i'), ('c', [5, 1])]] # readout layer\n",
    "    ]\n",
    "\n",
    "class GammaNet(tf.keras.Model):\n",
    "    '''\n",
    "    Gamma-net class\n",
    "    '''\n",
    "    def __init__(self, batch_size=1, steps=1, blocks_config = default_config, mode='segmentation'):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = len(blocks_config) - 1\n",
    "        self.steps = steps\n",
    "        self.blocks_config = blocks_config\n",
    "        self.blocks = [] # stores gammanetblocks, number of items equals number \n",
    "                         # of layers, each layer contains one or two blocks.\n",
    "        self.mode = mode\n",
    "\n",
    "        for i in range(self.n_layers + 1):\n",
    "        # for all layers:\n",
    "            block_config = self.blocks_config[i]\n",
    "            input_shape = block_config[0]\n",
    "            block = []\n",
    "            for j in range(1, len(block_config)):\n",
    "                block.append(GammaNetBlock(self.batch_size, input_shape, block_config[j]))\n",
    "            self.blocks.append(block)\n",
    "            \n",
    "    def get_output(self, x):\n",
    "        for _ in range(self.steps):\n",
    "            z = x \n",
    "            # In the paper, this assignment appears before the time loop,\n",
    "            # and updates z on the first layer with ReLU and Conv every time \n",
    "            # step. \n",
    "            # This doesn't make much sense, because at time t, the input\n",
    "            # to the first layer would already gone through t-1 ReLU and Convs,\n",
    "            # but when you consider human brain, every second comes a fresh image\n",
    "            # from the very bottom of the visual path.\n",
    "            for l in range(self.n_layers):\n",
    "            # bottom-up\n",
    "                if l == self.n_layers-1:\n",
    "                    h = self.blocks[l][0].hidden_state\n",
    "                else: h = self.blocks[l][1].hidden_state\n",
    "                if h == None:\n",
    "                # if no initial hidden_state, assign h as 0.\n",
    "                # note that the input_shape_ of gammaNetBlock objects contains\n",
    "                # batch_size aat the begginning already.\n",
    "                    h = tf.zeros(self.blocks[l][0].input_shape_)\n",
    "                z = self.blocks[l][0](z, h)\n",
    "            \n",
    "            for l in range(self.n_layers-2, -1, -1):\n",
    "            # top-down\n",
    "                h = self.blocks[l][0].hidden_state\n",
    "                z = self.blocks[l][1](z, h)\n",
    "\n",
    "    def call(self, x):\n",
    "        for _ in range(self.steps):\n",
    "            z = x \n",
    "            # In the paper, this assignment appears before the time loop,\n",
    "            # and updates z on the first layer with ReLU and Conv every time \n",
    "            # step. \n",
    "            # This doesn't make much sense, because at time t, the input\n",
    "            # to the first layer would already gone through t-1 ReLU and Convs,\n",
    "            # but when you consider human brain, every second comes a fresh image\n",
    "            # from the very bottom of the visual path.\n",
    "            for l in range(self.n_layers):\n",
    "            # bottom-up\n",
    "                if l == self.n_layers-1:\n",
    "                    pos = 0\n",
    "                else: pos = 1\n",
    "                h = tf.zeros(self.blocks[l][pos].input_shape_)\n",
    "                z = self.blocks[l][0](z, h)\n",
    "            \n",
    "            for l in range(self.n_layers-2, -1, -1):\n",
    "            # top-down\n",
    "                h = self.blocks[l][0].hidden_state\n",
    "                z = self.blocks[l][1](z, h)\n",
    "        if self.mode == 'segmentation':\n",
    "            out = self.blocks[-1][0](z, None)\n",
    "        elif self.mode == 'classification': \n",
    "            out = self.blocks[-1][0](self.blocks[self.n_layers-1][0].hidden_state, None)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNet = GammaNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.00000000e+00 4.32764318e-05 8.10029633e-07 ... 0.00000000e+00\n",
      "    0.00000000e+00 4.34857648e-05]\n",
      "   [0.00000000e+00 5.87533323e-05 0.00000000e+00 ... 2.43774048e-05\n",
      "    0.00000000e+00 4.58322975e-05]\n",
      "   [0.00000000e+00 1.41478358e-05 9.41691724e-07 ... 0.00000000e+00\n",
      "    1.75382102e-05 4.51710512e-05]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 1.10112251e-06 ... 0.00000000e+00\n",
      "    2.31475042e-05 1.80980605e-05]\n",
      "   [0.00000000e+00 1.63596487e-05 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.18468140e-06 7.59661179e-06]\n",
      "   [7.10298173e-06 1.40269894e-05 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 1.18805656e-05 0.00000000e+00 ... 5.79135594e-05\n",
      "    0.00000000e+00 5.49850993e-05]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 5.22956398e-05\n",
      "    0.00000000e+00 2.55932973e-05]\n",
      "   [0.00000000e+00 4.80036288e-05 0.00000000e+00 ... 4.30816144e-05\n",
      "    0.00000000e+00 9.49998503e-05]\n",
      "   ...\n",
      "   [3.36376002e-06 0.00000000e+00 0.00000000e+00 ... 5.49829974e-06\n",
      "    0.00000000e+00 2.90843782e-05]\n",
      "   [0.00000000e+00 0.00000000e+00 6.99372958e-06 ... 2.48650867e-05\n",
      "    1.63075638e-05 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.08372578e-05\n",
      "    3.01104392e-05 1.74472643e-05]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 8.21915382e-05\n",
      "    0.00000000e+00 1.20004130e-04]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 8.59329812e-05\n",
      "    0.00000000e+00 1.44927486e-04]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.84022792e-05\n",
      "    0.00000000e+00 2.30241967e-05]\n",
      "   ...\n",
      "   [2.49068580e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    8.52995981e-06 2.25945078e-05]\n",
      "   [5.37183769e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 6.65636435e-06]\n",
      "   [2.53702474e-05 1.39709300e-07 2.08149436e-06 ... 0.00000000e+00\n",
      "    2.57035554e-05 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.10672627e-04\n",
      "    0.00000000e+00 1.01403122e-04]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.14286486e-04\n",
      "    0.00000000e+00 6.60694495e-05]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 9.81464254e-05\n",
      "    1.54001027e-05 2.21115861e-05]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.98737666e-06 1.46057000e-05]\n",
      "   [5.86530914e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.80415543e-06 0.00000000e+00]\n",
      "   [5.56770319e-05 5.18242632e-06 2.98327977e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.38942603e-04\n",
      "    0.00000000e+00 9.66606385e-05]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.46433857e-04\n",
      "    0.00000000e+00 6.94767441e-05]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 8.62248635e-05\n",
      "    0.00000000e+00 4.48951541e-05]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 6.06664798e-06\n",
      "    0.00000000e+00 4.76186397e-05]\n",
      "   [4.27900122e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.85712701e-06 0.00000000e+00]\n",
      "   [4.98729605e-05 5.18737033e-06 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.87640612e-05 0.00000000e+00]]\n",
      "\n",
      "  [[8.81767119e-06 0.00000000e+00 0.00000000e+00 ... 8.64791000e-05\n",
      "    0.00000000e+00 7.24964775e-05]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 6.57788114e-05\n",
      "    0.00000000e+00 3.62933570e-05]\n",
      "   [0.00000000e+00 0.00000000e+00 1.80281113e-05 ... 3.72425129e-05\n",
      "    4.76803179e-05 5.71795827e-05]\n",
      "   ...\n",
      "   [1.60632135e-05 0.00000000e+00 1.78441696e-05 ... 1.96263341e-06\n",
      "    2.34191448e-05 0.00000000e+00]\n",
      "   [6.86860294e-05 0.00000000e+00 0.00000000e+00 ... 3.15969965e-06\n",
      "    4.95089625e-05 0.00000000e+00]\n",
      "   [5.20292997e-05 0.00000000e+00 1.44922169e-05 ... 1.25028805e-06\n",
      "    1.61133084e-05 0.00000000e+00]]]], shape=(1, 384, 384, 24), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "image = np.random.rand(1, 384, 384, 24)\n",
    "out = testNet(image)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[3.66100252e-01 2.87641823e-01 2.52678208e-02 ... 4.29280251e-01\n",
      "    3.48325878e-01 1.40824050e-01]\n",
      "   [1.43614843e-01 3.41969699e-01 6.24147616e-02 ... 3.15974355e-01\n",
      "    4.14131135e-01 7.29575008e-02]\n",
      "   [2.32048586e-01 2.33579293e-01 4.46975529e-01 ... 3.33756924e-01\n",
      "    4.10192937e-01 2.35022187e-01]\n",
      "   ...\n",
      "   [7.10494742e-02 1.25166088e-01 3.13693613e-01 ... 3.57219875e-02\n",
      "    4.25390750e-01 4.12459195e-01]\n",
      "   [3.81193757e-01 4.34275091e-01 3.60676289e-01 ... 1.59671694e-01\n",
      "    1.57082990e-01 1.70408547e-01]\n",
      "   [3.07462156e-01 3.64185236e-02 4.73077059e-01 ... 4.07286823e-01\n",
      "    2.90528893e-01 4.81497020e-01]]\n",
      "\n",
      "  [[4.41718400e-01 4.30781811e-01 1.14224508e-01 ... 9.48649645e-03\n",
      "    2.93744475e-01 2.43767917e-01]\n",
      "   [1.74163237e-01 3.92020971e-01 6.54795468e-02 ... 3.65524381e-01\n",
      "    7.87539110e-02 4.44264084e-01]\n",
      "   [2.95827091e-01 4.03627694e-01 8.12440887e-02 ... 1.24102861e-01\n",
      "    4.53640610e-01 4.17754203e-01]\n",
      "   ...\n",
      "   [4.13201094e-01 2.87497520e-01 3.99560213e-01 ... 3.68160099e-01\n",
      "    2.74241883e-02 1.00662112e-02]\n",
      "   [3.12067777e-01 2.65676677e-01 2.08494440e-01 ... 1.08878851e-01\n",
      "    1.08372934e-01 1.10497465e-02]\n",
      "   [4.87760037e-01 1.24025501e-01 1.46902695e-01 ... 3.54245216e-01\n",
      "    2.27748722e-01 3.86242598e-01]]\n",
      "\n",
      "  [[2.82213479e-01 8.79107490e-02 1.40277846e-02 ... 4.77865189e-01\n",
      "    3.59294027e-01 4.48090792e-01]\n",
      "   [4.93931025e-01 3.43515903e-01 1.06680296e-01 ... 4.77527887e-01\n",
      "    2.10693568e-01 3.85670692e-01]\n",
      "   [1.06103748e-01 2.15832010e-01 9.13208053e-02 ... 1.22742519e-01\n",
      "    1.19561337e-01 4.76503193e-01]\n",
      "   ...\n",
      "   [3.05831492e-01 1.22743562e-01 2.81905234e-01 ... 2.75547475e-01\n",
      "    3.94635051e-01 4.72750843e-01]\n",
      "   [5.06916165e-01 4.15852368e-01 2.39689693e-01 ... 2.19716012e-01\n",
      "    9.16543528e-02 3.14036161e-01]\n",
      "   [3.92533302e-01 2.20179886e-01 4.37065333e-01 ... 4.12606508e-01\n",
      "    2.79525518e-01 2.06685275e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.21840346e-01 4.68627930e-01 4.17545587e-01 ... 3.99616629e-01\n",
      "    2.31853187e-01 1.65297776e-01]\n",
      "   [4.66079712e-01 1.02417596e-01 4.10724372e-01 ... 1.71507239e-01\n",
      "    3.20451170e-01 3.75508040e-01]\n",
      "   [4.79778349e-01 1.39268875e-01 3.99906784e-01 ... 1.98600978e-01\n",
      "    1.96385443e-01 2.22524628e-01]\n",
      "   ...\n",
      "   [4.15272504e-01 3.46663177e-01 3.81809980e-01 ... 1.55909359e-01\n",
      "    2.01880127e-01 4.77412641e-01]\n",
      "   [4.27332997e-01 4.83430088e-01 8.80724266e-02 ... 3.66134495e-01\n",
      "    8.06432441e-02 1.01514421e-01]\n",
      "   [4.32310909e-01 4.71592665e-01 3.33901227e-01 ... 2.61927675e-03\n",
      "    3.93296868e-01 2.70820588e-01]]\n",
      "\n",
      "  [[2.98475355e-01 2.58157164e-01 8.18987340e-02 ... 4.49544340e-01\n",
      "    3.65449518e-01 2.06448719e-01]\n",
      "   [2.08777592e-01 2.02904597e-01 1.19049363e-02 ... 7.79336765e-02\n",
      "    9.14698392e-02 7.00420067e-02]\n",
      "   [3.42958927e-01 2.64207095e-01 1.64890617e-01 ... 2.17884257e-01\n",
      "    1.34314090e-01 1.47855699e-01]\n",
      "   ...\n",
      "   [2.09230751e-01 5.39901108e-02 2.42313847e-01 ... 4.57370877e-02\n",
      "    1.05879843e-01 4.80358839e-01]\n",
      "   [2.60394514e-01 1.74725607e-01 2.71399468e-02 ... 4.53065485e-01\n",
      "    3.37038517e-01 1.07808098e-01]\n",
      "   [1.16582967e-01 1.97528541e-01 1.05827540e-01 ... 2.95782119e-01\n",
      "    4.72484976e-01 6.32334277e-02]]\n",
      "\n",
      "  [[1.33925378e-01 3.49869639e-01 2.02667430e-01 ... 3.74721795e-01\n",
      "    7.65394643e-02 4.89083007e-02]\n",
      "   [3.85274440e-01 5.74580804e-02 2.97772795e-01 ... 2.35676691e-01\n",
      "    4.47415978e-01 3.89423966e-02]\n",
      "   [2.65889652e-02 4.29633975e-01 3.78519326e-01 ... 1.29313514e-01\n",
      "    3.64449918e-01 5.00023007e-01]\n",
      "   ...\n",
      "   [9.01530385e-02 2.85482734e-01 1.68618321e-01 ... 2.59833783e-02\n",
      "    3.34504753e-01 2.21604168e-01]\n",
      "   [3.10520649e-01 1.01371810e-01 1.65386036e-01 ... 1.04860261e-01\n",
      "    1.66609958e-01 2.44544353e-02]\n",
      "   [3.45095724e-01 1.12801030e-01 4.40207034e-01 ... 2.75378406e-01\n",
      "    2.98104882e-01 2.34940633e-01]]]\n",
      "\n",
      "\n",
      " [[[4.90782291e-01 2.97122270e-01 4.53825325e-01 ... 4.03805643e-01\n",
      "    4.41275477e-01 3.30493122e-01]\n",
      "   [3.37801099e-01 3.36842299e-01 4.37677711e-01 ... 1.11241713e-01\n",
      "    2.82726049e-01 3.40191275e-01]\n",
      "   [4.69019234e-01 4.15642142e-01 3.47146541e-01 ... 3.08955401e-01\n",
      "    2.14979470e-01 2.94097185e-01]\n",
      "   ...\n",
      "   [9.89267454e-02 1.25565588e-01 2.51038283e-01 ... 2.98962891e-01\n",
      "    1.98018402e-01 4.31211412e-01]\n",
      "   [3.51396322e-01 2.55395025e-01 1.32469118e-01 ... 4.08348620e-01\n",
      "    3.07824880e-01 1.96764544e-01]\n",
      "   [6.76787719e-02 1.03101306e-01 1.66686609e-01 ... 4.12570417e-01\n",
      "    8.94712806e-02 3.12633097e-01]]\n",
      "\n",
      "  [[2.73055464e-01 4.21514213e-02 4.99963343e-01 ... 4.53643948e-01\n",
      "    3.92987370e-01 3.01206440e-01]\n",
      "   [9.46039632e-02 7.07072914e-02 3.33975613e-01 ... 4.64623898e-01\n",
      "    1.70559525e-01 2.19505340e-01]\n",
      "   [3.28838155e-02 3.08464319e-01 4.57517028e-01 ... 2.10029617e-01\n",
      "    4.21819597e-01 2.99770147e-01]\n",
      "   ...\n",
      "   [1.89135090e-01 4.08136755e-01 3.94530714e-01 ... 1.69412136e-01\n",
      "    3.38071436e-01 3.90597105e-01]\n",
      "   [1.08921967e-01 1.89811751e-01 2.19076321e-01 ... 2.74199881e-02\n",
      "    4.75828677e-01 2.61913985e-01]\n",
      "   [9.88162607e-02 2.70730644e-01 2.69958913e-01 ... 4.60083485e-01\n",
      "    2.01206326e-01 8.55528861e-02]]\n",
      "\n",
      "  [[2.19810635e-01 6.33921623e-02 1.72238320e-01 ... 1.39491424e-01\n",
      "    4.08798993e-01 1.99314535e-01]\n",
      "   [4.37644631e-01 3.40281844e-01 2.96118319e-01 ... 3.89628023e-01\n",
      "    3.93709466e-02 2.88177520e-01]\n",
      "   [1.50556967e-01 2.62775540e-01 3.54642451e-01 ... 3.07827264e-01\n",
      "    2.40952238e-01 1.53448150e-01]\n",
      "   ...\n",
      "   [1.62494302e-01 4.76869792e-02 3.15167367e-01 ... 2.34147049e-02\n",
      "    3.79688203e-01 3.46566796e-01]\n",
      "   [2.47167081e-01 3.86785299e-01 3.56403947e-01 ... 4.77191173e-02\n",
      "    3.64866883e-01 2.07339585e-01]\n",
      "   [4.21368331e-01 2.94667810e-01 2.74016052e-01 ... 1.45756118e-02\n",
      "    2.93098867e-01 1.25181466e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[4.04703528e-01 1.30026847e-01 1.30698159e-01 ... 1.14884280e-01\n",
      "    2.26593554e-01 4.14422005e-01]\n",
      "   [2.87661463e-01 3.12479287e-01 2.67136365e-01 ... 5.07349707e-02\n",
      "    5.73070236e-02 4.12667878e-02]\n",
      "   [7.29243830e-02 1.68783590e-02 3.27831000e-01 ... 2.78483391e-01\n",
      "    4.36933249e-01 4.36566532e-01]\n",
      "   ...\n",
      "   [4.55091983e-01 4.57648873e-01 3.93202901e-01 ... 1.92639947e-01\n",
      "    1.25659451e-01 4.67235655e-01]\n",
      "   [1.69169709e-01 4.49844450e-01 3.03536743e-01 ... 2.34405354e-01\n",
      "    1.56940043e-01 4.42690969e-01]\n",
      "   [3.43429416e-01 1.44609988e-01 1.56999677e-01 ... 5.04962914e-02\n",
      "    3.50671858e-01 2.38154396e-01]]\n",
      "\n",
      "  [[3.72897655e-01 4.52778637e-01 4.86962676e-01 ... 2.89993674e-01\n",
      "    6.29049391e-02 1.41588837e-01]\n",
      "   [4.35479641e-01 2.78358102e-01 3.82369548e-01 ... 1.66857839e-01\n",
      "    4.32539791e-01 7.67747983e-02]\n",
      "   [1.01272136e-01 2.57747602e-02 1.15425825e-01 ... 1.74841821e-01\n",
      "    1.08193263e-01 5.43874316e-02]\n",
      "   ...\n",
      "   [1.90290228e-01 1.28850162e-01 2.60878205e-01 ... 4.50225562e-01\n",
      "    3.85472000e-01 2.95308173e-01]\n",
      "   [6.96107075e-02 1.33061945e-01 3.97607172e-03 ... 2.75442153e-01\n",
      "    1.47113144e-01 4.00768131e-01]\n",
      "   [1.17556617e-01 1.04664862e-01 4.37358260e-01 ... 1.93858787e-01\n",
      "    1.85580030e-01 6.58286661e-02]]\n",
      "\n",
      "  [[2.26114079e-01 1.49494380e-01 6.38322979e-02 ... 1.55438911e-02\n",
      "    3.19018900e-01 2.45662645e-01]\n",
      "   [1.86201900e-01 1.60244301e-01 1.93975791e-01 ... 4.14676368e-01\n",
      "    5.44474879e-03 3.50430310e-01]\n",
      "   [3.70218009e-01 1.56608135e-01 3.27146053e-01 ... 4.83036071e-01\n",
      "    3.32322508e-01 2.02715263e-01]\n",
      "   ...\n",
      "   [5.24000168e-01 3.38441610e-01 2.62498200e-01 ... 2.15097815e-01\n",
      "    1.44405648e-01 3.16078514e-01]\n",
      "   [3.71828914e-01 1.30672231e-01 3.17668393e-02 ... 4.17170551e-04\n",
      "    3.08776706e-01 7.61752278e-02]\n",
      "   [1.62776709e-01 1.37489408e-01 2.92543679e-01 ... 4.43013310e-02\n",
      "    1.83957458e-01 1.74890012e-01]]]], shape=(2, 24, 24, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "testCell = fGRU.fGRU([2, 24, 24, 64])\n",
    "\n",
    "image = np.random.rand(2, 24, 24, 64)\n",
    "H = np.random.rand(2, 24, 24, 64)\n",
    "\n",
    "out = testCell(image, H)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gamma_net_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 14,400,117\n",
      "Trainable params: 797,301\n",
      "Non-trainable params: 13,602,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "testNet.build([1, 384, 384, 24])\n",
    "testNet.compile(optimizer=tf.optimizers.Adam(), loss='mse')\n",
    "testNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "## Run functions eagerly to allow numpy conversions.\n",
    "## Enable experimental debug mode to suppress warning (feel free to remove second line)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    \"\"\"\n",
    "    Loads CIFAR10 training and testing datasets\n",
    "\n",
    "    :return X0: training images,\n",
    "            Y0: training labels,\n",
    "            X1: testing images,\n",
    "            Y1: testing labels\n",
    "            D0: TF Dataset training subset\n",
    "            D1: TF Dataset testing subset\n",
    "        D_info: TF Dataset metadata\n",
    "    \"\"\"\n",
    "\n",
    "    ## This process may take a bit to load the first time; should get much faster\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    ## Overview of dataset downloading: https://www.tensorflow.org/datasets/catalog/overview\n",
    "    ## CIFAR-10 Dataset https://www.tensorflow.org/datasets/catalog/cifar10\n",
    "    (D0, D1), D_info = tfds.load(\n",
    "        \"cifar10\", as_supervised=True, split=[\"train[:50%]\", \"test\"], with_info=True\n",
    "    )\n",
    "\n",
    "    X0, X1 = [np.array([r[0] for r in tfds.as_numpy(D)]) for D in (D0, D1)]\n",
    "    Y0, Y1 = [np.array([r[1] for r in tfds.as_numpy(D)]) for D in (D0, D1)]\n",
    "\n",
    "    return X0, Y0, X1, Y1, D0, D1, D_info\n",
    "\n",
    "X0, Y0, X1, Y1, D0, D1, D_info = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_config = [\n",
    "    [[32, 32, 3], \n",
    "     [('c', [3, 1]), ('c', [3, 1]), ('f', [9, False]), ('m', [2, 2])],\n",
    "     [('t', [4, 2]),('c', [3, 1]),('i'),('f', [1, False])]], # first layer\n",
    "    [[16, 16, 5], \n",
    "     [('c', [3, 1]), ('f', [7, False]), ('m', [2, 2])],\n",
    "     [('t', [4, 2]),('c', [3, 1]),('i'),('f', [1, False])]], # second layer\n",
    "    [[8, 8, 10], \n",
    "     [('c', [3, 1]), ('f', [5, False]), ('m', [2, 2])],\n",
    "     [('t', [4, 2]),('c', [3, 1]),('i'),('f', [1, False])]], # third layer\n",
    "    [[4, 4, 20], \n",
    "     [('c', [3, 1]), ('f', [3, False])],], # forth layer # fifth layer\n",
    "    [[4, 4, 20], [('i'), ('l'), ('d', [100, 'l']), ('d', [10, 's'])]] # readout layer\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GammaNet(steps = 4, blocks_config = classification_config, mode='classification')\n",
    "model.build([1, 32, 32, 3])\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gamma_net_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 79,017\n",
      "Trainable params: 68,393\n",
      "Non-trainable params: 10,624\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = np.array(tf.cast(Y0, 'float32'))\n",
    "Y1 = np.array(tf.cast(Y1, 'float32'))\n",
    "X0 = np.array(tf.cast(X0, 'float32'))\n",
    "X1 = np.array(tf.cast(X1, 'float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32, 3)\n",
      "(25000, 10)\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<keras.losses.CategoricalCrossentropy object at 0x16c55c760>) with an unsupported type (<class 'keras.losses.CategoricalCrossentropy'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yixiangsun/Brown/2023spring/CSCI1952Q/RecurrentFeedbackCNN/exploration.ipynb Cell 12\u001b[0m in \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yixiangsun/Brown/2023spring/CSCI1952Q/RecurrentFeedbackCNN/exploration.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m Y0 \u001b[39m=\u001b[39m output_prep_fn(Y0)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yixiangsun/Brown/2023spring/CSCI1952Q/RecurrentFeedbackCNN/exploration.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(Y0\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yixiangsun/Brown/2023spring/CSCI1952Q/RecurrentFeedbackCNN/exploration.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X0, Y0, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (X1, output_prep_fn(Y1)))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dl3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    105\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (<keras.losses.CategoricalCrossentropy object at 0x16c55c760>) with an unsupported type (<class 'keras.losses.CategoricalCrossentropy'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "print(X0.shape)\n",
    "output_prep_fn = tf.keras.layers.CategoryEncoding(\n",
    "        num_tokens=10, output_mode=\"one_hot\"\n",
    "    )\n",
    "\n",
    "Y0 = output_prep_fn(Y0)\n",
    "print(Y0.shape)\n",
    "history = model.fit(X0, Y0, batch_size=1, epochs=2, validation_data = (X1, output_prep_fn(Y1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
